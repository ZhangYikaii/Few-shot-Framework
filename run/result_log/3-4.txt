{'augment': False,
 'backbone_class': 'ConvNet',
 'balance': 1.0,
 'batch_size': 16,
 'cuda_seed': 929,
 'data_path': '/mnt/data3/lus/zhangyk/data/ye',
 'dataset': 'MiniImageNet',
 'distance': 'l2',
 'drop_lr_every': 40,
 'episodes_per_test_epoch': 10000,
 'episodes_per_train_epoch': 200,
 'episodes_per_val_epoch': 200,
 'epoch_verbose': False,
 'fce': False,
 'fix_BN': False,
 'gamma': 0.6,
 'gpu': '3',
 'init_weights': None,
 'inner_lr': 0.4,
 'inner_train_steps': 1,
 'inner_val_steps': 3,
 'log_interval': 50,
 'logger_filename': '/logs',
 'loss_fn': 'nn-cross_entropy',
 'lr': 0.0001,
 'lr_mul': 10.0,
 'lr_scheduler': 'step',
 'matching_lstm_layers': 1,
 'matching_unrolling_steps': 2,
 'max_epoch': 200,
 'meta': False,
 'meta_batch_size': 1,
 'meta_lr': 0.001,
 'metric_func': 'categorical_accuracy',
 'metrics': 'categorical_accuracy',
 'model_class': 'ProtoNet',
 'model_filepath': '/mnt/data3/lus/zhangyk/models/ProtoNet/0222 14-56-50-227 '
                   'ProtoNet MiniImageNet ConvNet-backbone l2 '
                   '5-1-15_train-w-s-q 5-1-15_val-w-s-q 5-1-15_test-w-s-q.pth',
 'model_filepath_test_best': '/mnt/data3/lus/zhangyk/models/ProtoNet/test_best/0222 '
                             '14-56-50-227 ProtoNet MiniImageNet '
                             'ConvNet-backbone l2 5-1-15_train-w-s-q '
                             '5-1-15_val-w-s-q 5-1-15_test-w-s-q.pth',
 'model_save_path': '/mnt/data3/lus/zhangyk/models',
 'mom': 0.9,
 'np_seed': 929,
 'num_input_channels': 3,
 'num_tasks': 4,
 'num_workers': 4,
 'order': 1,
 'orig_imsize': -1,
 'params_str': '0222 14-56-50-227 ProtoNet MiniImageNet ConvNet-backbone l2 '
               '5-1-15_train-w-s-q 5-1-15_val-w-s-q 5-1-15_test-w-s-q',
 'pretrain_mode': False,
 'relation_hidden_dim': 8,
 'save_dir': './checkpoints',
 'simpleshot': False,
 'simpleshot_episodes_per_epoch': 100,
 'simpleshot_num_nn': 1,
 'step_size': '20',
 'temperature': 64.0,
 'temperature2': 16.0,
 'test_interval': 0,
 'test_model_filepath': None,
 'test_query': 15,
 'test_shot': 1,
 'test_way': 5,
 'time_str': '0222 14-56-50-227',
 'torch_seed': 929,
 'train_mode': True,
 'train_query': 15,
 'train_shot': 1,
 'train_way': 5,
 'val_interval': 1,
 'val_query': 15,
 'val_shot': 1,
 'val_way': 5,
 'verbose': True,
 'weight_decay': 0.0005,
 'z_comment': 'Here are some comments for the current training process.'}
Begin training...
Epoch: 1:
{'categorical_accuracy': 0.2943999999999999, 'val_loss': 0.00783457815349102}
Best val_ accuracy: 0.2944.
ETA: 9m -> 30.8h.

Epoch: 2:
{'categorical_accuracy': 0.3069333333333334, 'val_loss': 0.007787570309638977}
Best val_ accuracy: 0.3069.
ETA: 21m -> 35.8h.

Epoch: 3:
{'categorical_accuracy': 0.3081999999999999, 'val_loss': 0.007743392556905746}
Best val_ accuracy: 0.3082.
ETA: 35m -> 39.1h.

Epoch: 4:
{'categorical_accuracy': 0.3174666666666667, 'val_loss': 0.007721980041265488}
Best val_ accuracy: 0.3175.
ETA: 49m -> 40.5h.

Epoch: 5:
{'categorical_accuracy': 0.3333333333333332, 'val_loss': 0.007678779426217079}
Best val_ accuracy: 0.3333.
ETA: 1.0h -> 41.4h.

Epoch: 6:
{'categorical_accuracy': 0.3284666666666667, 'val_loss': 0.007682003289461135}
ETA: 1.3h -> 42.2h.

Epoch: 7:
{'categorical_accuracy': 0.32226666666666676, 'val_loss': 0.007648989573121071}
ETA: 1.5h -> 41.9h.

Epoch: 8:
{'categorical_accuracy': 0.33619999999999967, 'val_loss': 0.007672036790847778}
Best val_ accuracy: 0.3362.
ETA: 1.7h -> 41.9h.

Epoch: 9:
{'categorical_accuracy': 0.32886666666666664, 'val_loss': 0.0076423309624195105}
ETA: 1.9h -> 42.2h.

Epoch: 10:
{'categorical_accuracy': 0.359, 'val_loss': 0.007479847338795662}
Best val_ accuracy: 0.3590.
ETA: 2.1h -> 42.3h.

Epoch: 11:
{'categorical_accuracy': 0.3373999999999999, 'val_loss': 0.007601084551215172}
ETA: 2.3h -> 42.1h.

Epoch: 12:
{'categorical_accuracy': 0.3579333333333331, 'val_loss': 0.007475385698676109}
ETA: 2.5h -> 42.2h.

Epoch: 13:
{'categorical_accuracy': 0.3714666666666666, 'val_loss': 0.007399103191494941}
Best val_ accuracy: 0.3715.
ETA: 2.7h -> 42.0h.

Epoch: 14:
{'categorical_accuracy': 0.3692666666666666, 'val_loss': 0.0074345896780490875}
ETA: 2.9h -> 41.8h.

Epoch: 15:
{'categorical_accuracy': 0.3681333333333331, 'val_loss': 0.007391094508767127}
ETA: 3.1h -> 41.6h.

Epoch: 16:
{'categorical_accuracy': 0.3490666666666666, 'val_loss': 0.00748392963707447}
ETA: 3.3h -> 41.2h.

Epoch: 17:
{'categorical_accuracy': 0.37213333333333287, 'val_loss': 0.0073737020015716545}
Best val_ accuracy: 0.3721.
ETA: 3.5h -> 40.9h.

Epoch: 18:
{'categorical_accuracy': 0.37593333333333306, 'val_loss': 0.007406131789088249}
Best val_ accuracy: 0.3759.
ETA: 3.7h -> 40.9h.

Epoch: 19:
{'categorical_accuracy': 0.3690666666666663, 'val_loss': 0.00740161080956459}
ETA: 3.9h -> 40.8h.

Epoch: 20:
{'categorical_accuracy': 0.37573333333333314, 'val_loss': 0.0073355055183172225}
ETA: 4.1h -> 40.9h.

Epoch: 21:
{'categorical_accuracy': 0.3768666666666667, 'val_loss': 0.00731859864294529}
Best val_ accuracy: 0.3769.
ETA: 4.3h -> 40.8h.

Epoch: 22:
{'categorical_accuracy': 0.373, 'val_loss': 0.007375984013080597}
ETA: 4.5h -> 40.6h.

Epoch: 23:
{'categorical_accuracy': 0.37753333333333317, 'val_loss': 0.007295782682299614}
Best val_ accuracy: 0.3775.
ETA: 4.7h -> 40.5h.

Epoch: 24:
{'categorical_accuracy': 0.37373333333333314, 'val_loss': 0.0073476622402668}
ETA: 4.8h -> 40.3h.

Epoch: 25:
{'categorical_accuracy': 0.3821999999999999, 'val_loss': 0.00730125330388546}
Best val_ accuracy: 0.3822.
ETA: 5.0h -> 40.1h.

Epoch: 26:
{'categorical_accuracy': 0.3783333333333333, 'val_loss': 0.007274878868460654}
ETA: 5.2h -> 39.7h.

Epoch: 27:
{'categorical_accuracy': 0.38119999999999943, 'val_loss': 0.0073025240063667295}
ETA: 5.3h -> 39.4h.

Epoch: 28:
{'categorical_accuracy': 0.3818666666666667, 'val_loss': 0.007306179684400559}
ETA: 5.5h -> 39.1h.

Epoch: 29:
{'categorical_accuracy': 0.39499999999999974, 'val_loss': 0.007245816212892532}
Best val_ accuracy: 0.3950.
ETA: 5.6h -> 38.9h.

Epoch: 30:
{'categorical_accuracy': 0.3881999999999997, 'val_loss': 0.007261065402626991}
ETA: 5.8h -> 38.5h.

Epoch: 31:
{'categorical_accuracy': 0.3844666666666667, 'val_loss': 0.007273466432094574}
ETA: 5.9h -> 38.3h.

Epoch: 32:
{'categorical_accuracy': 0.39239999999999997, 'val_loss': 0.007215670457482338}
ETA: 6.1h -> 38.0h.

Epoch: 33:
{'categorical_accuracy': 0.38786666666666647, 'val_loss': 0.007240565025806427}
ETA: 6.2h -> 37.7h.

Epoch: 34:
{'categorical_accuracy': 0.3883999999999999, 'val_loss': 0.007273985275626183}
ETA: 6.4h -> 37.5h.

Epoch: 35:
{'categorical_accuracy': 0.3699333333333332, 'val_loss': 0.007318718427419662}
ETA: 6.5h -> 37.2h.

Epoch: 36:
{'categorical_accuracy': 0.38979999999999954, 'val_loss': 0.007179444572329521}
ETA: 6.7h -> 37.0h.

Epoch: 37:
{'categorical_accuracy': 0.3848666666666666, 'val_loss': 0.0072064291864633555}
ETA: 6.8h -> 36.7h.

Epoch: 38:
{'categorical_accuracy': 0.4044666666666664, 'val_loss': 0.007073149791359902}
Best val_ accuracy: 0.4045.
ETA: 6.9h -> 36.4h.

Epoch: 39:
{'categorical_accuracy': 0.3967333333333329, 'val_loss': 0.007103378102183342}
ETA: 7.0h -> 36.1h.

Epoch: 40:
{'categorical_accuracy': 0.39666666666666667, 'val_loss': 0.007120794045925141}
ETA: 7.2h -> 35.9h.

Epoch: 41:
{'categorical_accuracy': 0.3921999999999998, 'val_loss': 0.007159227475523948}
ETA: 7.3h -> 35.6h.

Epoch: 42:
{'categorical_accuracy': 0.40773333333333334, 'val_loss': 0.007093420645594597}
Best val_ accuracy: 0.4077.
ETA: 7.4h -> 35.3h.

Epoch: 43:
{'categorical_accuracy': 0.4004666666666667, 'val_loss': 0.007140007230639458}
ETA: 7.5h -> 35.0h.

Epoch: 44:
{'categorical_accuracy': 0.3933333333333335, 'val_loss': 0.0071980561241507535}
ETA: 7.6h -> 34.8h.

Epoch: 45:
{'categorical_accuracy': 0.40006666666666646, 'val_loss': 0.007108269920945167}
ETA: 7.8h -> 34.5h.

Epoch: 46:
{'categorical_accuracy': 0.4090666666666668, 'val_loss': 0.0070853272259235375}
Best val_ accuracy: 0.4091.
ETA: 7.9h -> 34.2h.

Epoch: 47:
{'categorical_accuracy': 0.39433333333333337, 'val_loss': 0.007150015360116959}
ETA: 8.0h -> 34.0h.

Epoch: 48:
{'categorical_accuracy': 0.4045333333333332, 'val_loss': 0.007117150035500527}
ETA: 8.1h -> 33.7h.

Epoch: 49:
{'categorical_accuracy': 0.39726666666666643, 'val_loss': 0.007115818583965301}
ETA: 8.2h -> 33.5h.

Epoch: 50:
{'categorical_accuracy': 0.4129999999999999, 'val_loss': 0.007029721948504448}
Best val_ accuracy: 0.4130.
ETA: 8.3h -> 33.3h.

Epoch: 51:
{'categorical_accuracy': 0.4066000000000002, 'val_loss': 0.00708495767712593}
ETA: 8.4h -> 33.0h.

Epoch: 52:
{'categorical_accuracy': 0.38346666666666657, 'val_loss': 0.007185083654522896}
ETA: 8.5h -> 32.8h.

Epoch: 53:
{'categorical_accuracy': 0.39133333333333326, 'val_loss': 0.007112685281038284}
ETA: 8.6h -> 32.6h.

Epoch: 54:
{'categorical_accuracy': 0.3921333333333334, 'val_loss': 0.007109804637730121}
ETA: 8.7h -> 32.4h.

Epoch: 55:
{'categorical_accuracy': 0.3939333333333335, 'val_loss': 0.007145673751831054}
ETA: 8.9h -> 32.2h.

Epoch: 56:
{'categorical_accuracy': 0.40486666666666665, 'val_loss': 0.007055121350288391}
ETA: 9.0h -> 32.0h.

Epoch: 57:
{'categorical_accuracy': 0.40866666666666673, 'val_loss': 0.007007027772068978}
ETA: 9.1h -> 31.8h.

Epoch: 58:
{'categorical_accuracy': 0.3936666666666667, 'val_loss': 0.007043851923942566}
ETA: 9.2h -> 31.6h.

Epoch: 59:
{'categorical_accuracy': 0.4115999999999997, 'val_loss': 0.007083627942204475}
ETA: 9.3h -> 31.4h.

Epoch: 60:
{'categorical_accuracy': 0.40633333333333327, 'val_loss': 0.007037446102499963}
ETA: 9.4h -> 31.3h.

Epoch: 61:
{'categorical_accuracy': 0.40093333333333325, 'val_loss': 0.00705460210442543}
ETA: 9.5h -> 31.1h.

Epoch: 62:
{'categorical_accuracy': 0.41540000000000016, 'val_loss': 0.007027109757065772}
Best val_ accuracy: 0.4154.
ETA: 9.6h -> 31.0h.

Epoch: 63:
{'categorical_accuracy': 0.411933333333333, 'val_loss': 0.0069649828851223}
ETA: 9.7h -> 30.8h.

Epoch: 64:
{'categorical_accuracy': 0.40719999999999984, 'val_loss': 0.006998751786351204}
ETA: 9.8h -> 30.7h.

Epoch: 65:
{'categorical_accuracy': 0.41506666666666653, 'val_loss': 0.006998681458830833}
ETA: 9.9h -> 30.5h.

Epoch: 66:
{'categorical_accuracy': 0.4062666666666667, 'val_loss': 0.0070666564434766765}
ETA: 10.0h -> 30.4h.

Epoch: 67:
{'categorical_accuracy': 0.41313333333333313, 'val_loss': 0.007024664044380188}
ETA: 10.1h -> 30.3h.

Epoch: 68:
{'categorical_accuracy': 0.4069333333333332, 'val_loss': 0.00699246098101139}
ETA: 10.2h -> 30.1h.

Epoch: 69:
{'categorical_accuracy': 0.4034666666666665, 'val_loss': 0.00703453250527382}
ETA: 10.4h -> 30.1h.

Epoch: 70:
{'categorical_accuracy': 0.40480000000000005, 'val_loss': 0.007060664352774621}
ETA: 10.5h -> 30.1h.

