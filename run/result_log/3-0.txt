{'augment': False,
 'backbone_class': 'ConvNet',
 'balance': 1.0,
 'batch_size': 16,
 'cuda_seed': 929,
 'data_path': '/mnt/data3/lus/zhangyk/data/ye',
 'dataset': 'MiniImageNet',
 'distance': 'l2',
 'drop_lr_every': 40,
 'episodes_per_test_epoch': 10000,
 'episodes_per_train_epoch': 200,
 'episodes_per_val_epoch': 200,
 'epoch_verbose': False,
 'fce': False,
 'fix_BN': False,
 'gamma': 0.4,
 'gpu': '3',
 'init_weights': None,
 'inner_lr': 0.4,
 'inner_train_steps': 1,
 'inner_val_steps': 3,
 'log_interval': 50,
 'logger_filename': '/logs',
 'loss_fn': 'nn-cross_entropy',
 'lr': 0.001,
 'lr_mul': 10.0,
 'lr_scheduler': 'step',
 'matching_lstm_layers': 1,
 'matching_unrolling_steps': 2,
 'max_epoch': 200,
 'meta': False,
 'meta_batch_size': 1,
 'meta_lr': 0.001,
 'metric_func': 'categorical_accuracy',
 'metrics': 'categorical_accuracy',
 'model_class': 'ProtoNet',
 'model_filepath': '/mnt/data3/lus/zhangyk/models/ProtoNet/0222 14-55-10-310 '
                   'ProtoNet MiniImageNet ConvNet-backbone l2 '
                   '5-1-15_train-w-s-q 5-1-15_val-w-s-q 5-1-15_test-w-s-q.pth',
 'model_filepath_test_best': '/mnt/data3/lus/zhangyk/models/ProtoNet/test_best/0222 '
                             '14-55-10-310 ProtoNet MiniImageNet '
                             'ConvNet-backbone l2 5-1-15_train-w-s-q '
                             '5-1-15_val-w-s-q 5-1-15_test-w-s-q.pth',
 'model_save_path': '/mnt/data3/lus/zhangyk/models',
 'mom': 0.9,
 'np_seed': 929,
 'num_input_channels': 3,
 'num_tasks': 4,
 'num_workers': 4,
 'order': 1,
 'orig_imsize': -1,
 'params_str': '0222 14-55-10-310 ProtoNet MiniImageNet ConvNet-backbone l2 '
               '5-1-15_train-w-s-q 5-1-15_val-w-s-q 5-1-15_test-w-s-q',
 'pretrain_mode': False,
 'relation_hidden_dim': 8,
 'save_dir': './checkpoints',
 'simpleshot': False,
 'simpleshot_episodes_per_epoch': 100,
 'simpleshot_num_nn': 1,
 'step_size': '90',
 'temperature': 64.0,
 'temperature2': 16.0,
 'test_interval': 0,
 'test_model_filepath': None,
 'test_query': 15,
 'test_shot': 1,
 'test_way': 5,
 'time_str': '0222 14-55-10-310',
 'torch_seed': 929,
 'train_mode': True,
 'train_query': 15,
 'train_shot': 1,
 'train_way': 5,
 'val_interval': 1,
 'val_query': 15,
 'val_shot': 1,
 'val_way': 5,
 'verbose': True,
 'weight_decay': 0.0005,
 'z_comment': 'Here are some comments for the current training process.'}
Begin training...
Epoch: 1:
{'categorical_accuracy': 0.28893333333333326, 'val_loss': 0.0078287843644619}
Best val_ accuracy: 0.2889.
ETA: 9m -> 30.5h.

Epoch: 2:
{'categorical_accuracy': 0.29366666666666674, 'val_loss': 0.00784420460164547}
Best val_ accuracy: 0.2937.
ETA: 20m -> 33.9h.

Epoch: 3:
{'categorical_accuracy': 0.29613333333333336, 'val_loss': 0.007807882282137872}
Best val_ accuracy: 0.2961.
ETA: 34m -> 38.0h.

Epoch: 4:
{'categorical_accuracy': 0.3029999999999999, 'val_loss': 0.007799650323390961}
Best val_ accuracy: 0.3030.
ETA: 48m -> 40.0h.

Epoch: 5:
{'categorical_accuracy': 0.3090000000000001, 'val_loss': 0.0077276073485612875}
Best val_ accuracy: 0.3090.
ETA: 1.0h -> 40.9h.

Epoch: 6:
{'categorical_accuracy': 0.3206666666666667, 'val_loss': 0.007712230119109154}
Best val_ accuracy: 0.3207.
ETA: 1.3h -> 41.8h.

Epoch: 7:
{'categorical_accuracy': 0.3065333333333333, 'val_loss': 0.0077384211987257005}
ETA: 1.5h -> 41.5h.

Epoch: 8:
{'categorical_accuracy': 0.32779999999999987, 'val_loss': 0.007677752330899239}
Best val_ accuracy: 0.3278.
ETA: 1.7h -> 41.7h.

Epoch: 9:
{'categorical_accuracy': 0.30939999999999995, 'val_loss': 0.007907005408406258}
ETA: 1.9h -> 42.0h.

Epoch: 10:
{'categorical_accuracy': 0.3511333333333333, 'val_loss': 0.007518236768245697}
Best val_ accuracy: 0.3511.
ETA: 2.1h -> 42.2h.

Epoch: 11:
{'categorical_accuracy': 0.34399999999999975, 'val_loss': 0.007561343142390251}
ETA: 2.3h -> 42.1h.

Epoch: 12:
{'categorical_accuracy': 0.34313333333333335, 'val_loss': 0.007544330871105193}
ETA: 2.5h -> 42.1h.

Epoch: 13:
{'categorical_accuracy': 0.3616666666666664, 'val_loss': 0.007388032057881355}
Best val_ accuracy: 0.3617.
ETA: 2.7h -> 42.0h.

Epoch: 14:
{'categorical_accuracy': 0.3606666666666666, 'val_loss': 0.007428366571664811}
ETA: 2.9h -> 41.7h.

Epoch: 15:
{'categorical_accuracy': 0.3734, 'val_loss': 0.007334581562876701}
Best val_ accuracy: 0.3734.
ETA: 3.1h -> 41.6h.

Epoch: 16:
{'categorical_accuracy': 0.3600666666666665, 'val_loss': 0.007520192191004753}
ETA: 3.3h -> 41.2h.

Epoch: 17:
{'categorical_accuracy': 0.38446666666666673, 'val_loss': 0.007279042541980744}
Best val_ accuracy: 0.3845.
ETA: 3.5h -> 41.0h.

Epoch: 18:
{'categorical_accuracy': 0.3556666666666667, 'val_loss': 0.007535558518767357}
ETA: 3.7h -> 40.9h.

Epoch: 19:
{'categorical_accuracy': 0.3742666666666667, 'val_loss': 0.007317082667350769}
ETA: 3.9h -> 40.9h.

Epoch: 20:
{'categorical_accuracy': 0.381733333333333, 'val_loss': 0.00728468870818615}
ETA: 4.1h -> 40.9h.

Epoch: 21:
{'categorical_accuracy': 0.3853333333333331, 'val_loss': 0.007266635283827781}
Best val_ accuracy: 0.3853.
ETA: 4.3h -> 40.8h.

Epoch: 22:
{'categorical_accuracy': 0.37513333333333293, 'val_loss': 0.007243140810728073}
ETA: 4.5h -> 40.6h.

Epoch: 23:
{'categorical_accuracy': 0.3951333333333331, 'val_loss': 0.007125082552433014}
Best val_ accuracy: 0.3951.
ETA: 4.7h -> 40.5h.

Epoch: 24:
{'categorical_accuracy': 0.3927999999999999, 'val_loss': 0.0071676970511674876}
ETA: 4.8h -> 40.3h.

Epoch: 25:
{'categorical_accuracy': 0.3981333333333329, 'val_loss': 0.007128246334195137}
Best val_ accuracy: 0.3981.
ETA: 5.0h -> 40.1h.

Epoch: 26:
{'categorical_accuracy': 0.39573333333333316, 'val_loss': 0.0070713200151920315}
ETA: 5.2h -> 39.7h.

Epoch: 27:
{'categorical_accuracy': 0.3772666666666666, 'val_loss': 0.007383083614706993}
ETA: 5.3h -> 39.3h.

Epoch: 28:
{'categorical_accuracy': 0.3926666666666666, 'val_loss': 0.007196565344929695}
ETA: 5.5h -> 39.1h.

Epoch: 29:
{'categorical_accuracy': 0.4156666666666666, 'val_loss': 0.006977689644694328}
Best val_ accuracy: 0.4157.
ETA: 5.6h -> 38.8h.

Epoch: 30:
{'categorical_accuracy': 0.40459999999999985, 'val_loss': 0.0070407272726297375}
ETA: 5.8h -> 38.5h.

Epoch: 31:
{'categorical_accuracy': 0.40473333333333317, 'val_loss': 0.007105378788709641}
ETA: 5.9h -> 38.2h.

Epoch: 32:
{'categorical_accuracy': 0.4165999999999997, 'val_loss': 0.006980852308869362}
Best val_ accuracy: 0.4166.
ETA: 6.1h -> 37.9h.

Epoch: 33:
{'categorical_accuracy': 0.4216666666666664, 'val_loss': 0.006910340189933777}
Best val_ accuracy: 0.4217.
ETA: 6.2h -> 37.6h.

Epoch: 34:
{'categorical_accuracy': 0.4108666666666664, 'val_loss': 0.007118038246035577}
ETA: 6.3h -> 37.3h.

Epoch: 35:
{'categorical_accuracy': 0.3987999999999999, 'val_loss': 0.007102605503797531}
ETA: 6.5h -> 37.0h.

Epoch: 36:
{'categorical_accuracy': 0.40146666666666647, 'val_loss': 0.00704097948372364}
ETA: 6.6h -> 36.7h.

Epoch: 37:
{'categorical_accuracy': 0.40606666666666663, 'val_loss': 0.007003437477350235}
ETA: 6.8h -> 36.5h.

Epoch: 38:
{'categorical_accuracy': 0.4267999999999998, 'val_loss': 0.0068502920210361485}
Best val_ accuracy: 0.4268.
ETA: 6.9h -> 36.2h.

Epoch: 39:
{'categorical_accuracy': 0.4224666666666666, 'val_loss': 0.006886436282098294}
ETA: 7.0h -> 36.0h.

Epoch: 40:
{'categorical_accuracy': 0.4116666666666665, 'val_loss': 0.006875844195485115}
ETA: 7.1h -> 35.7h.

Epoch: 41:
{'categorical_accuracy': 0.4096666666666664, 'val_loss': 0.0069199127495288846}
ETA: 7.3h -> 35.5h.

Epoch: 42:
{'categorical_accuracy': 0.42720000000000014, 'val_loss': 0.006882706579566002}
Best val_ accuracy: 0.4272.
ETA: 7.4h -> 35.3h.

Epoch: 43:
{'categorical_accuracy': 0.4205333333333334, 'val_loss': 0.006938182923197747}
ETA: 7.5h -> 35.0h.

Epoch: 44:
{'categorical_accuracy': 0.4082666666666664, 'val_loss': 0.006998568642139435}
ETA: 7.7h -> 34.8h.

Epoch: 45:
{'categorical_accuracy': 0.4246666666666669, 'val_loss': 0.006895597375929355}
ETA: 7.8h -> 34.6h.

Epoch: 46:
{'categorical_accuracy': 0.43273333333333347, 'val_loss': 0.006755093330144882}
Best val_ accuracy: 0.4327.
ETA: 7.9h -> 34.4h.

Epoch: 47:
{'categorical_accuracy': 0.4156666666666664, 'val_loss': 0.006949506717920303}
ETA: 8.0h -> 34.1h.

Epoch: 48:
{'categorical_accuracy': 0.4252666666666665, 'val_loss': 0.006865624803304672}
ETA: 8.1h -> 33.8h.

Epoch: 49:
{'categorical_accuracy': 0.4268666666666664, 'val_loss': 0.006916992226243019}
ETA: 8.2h -> 33.6h.

Epoch: 50:
{'categorical_accuracy': 0.44420000000000004, 'val_loss': 0.00668268506526947}
Best val_ accuracy: 0.4442.
ETA: 8.3h -> 33.4h.

Epoch: 51:
{'categorical_accuracy': 0.4368666666666667, 'val_loss': 0.006760647991299629}
ETA: 8.5h -> 33.2h.

Epoch: 52:
{'categorical_accuracy': 0.41739999999999966, 'val_loss': 0.006874761709570885}
ETA: 8.6h -> 32.9h.

Epoch: 53:
{'categorical_accuracy': 0.4179333333333336, 'val_loss': 0.006838668172061443}
ETA: 8.7h -> 32.7h.

Epoch: 54:
{'categorical_accuracy': 0.4195333333333332, 'val_loss': 0.006880166359245777}
ETA: 8.8h -> 32.5h.

Epoch: 55:
{'categorical_accuracy': 0.4122, 'val_loss': 0.0069743613079190254}
ETA: 8.9h -> 32.3h.

Epoch: 56:
{'categorical_accuracy': 0.43799999999999994, 'val_loss': 0.006741234968602658}
ETA: 9.0h -> 32.1h.

Epoch: 57:
{'categorical_accuracy': 0.4333333333333335, 'val_loss': 0.006821965888142586}
ETA: 9.1h -> 31.9h.

Epoch: 58:
{'categorical_accuracy': 0.4234000000000001, 'val_loss': 0.006807663510739803}
ETA: 9.2h -> 31.7h.

Epoch: 59:
{'categorical_accuracy': 0.42193333333333327, 'val_loss': 0.006879391223192215}
ETA: 9.3h -> 31.5h.

Epoch: 60:
{'categorical_accuracy': 0.4332666666666667, 'val_loss': 0.006677078132331371}
ETA: 9.4h -> 31.4h.

Epoch: 61:
{'categorical_accuracy': 0.4243333333333334, 'val_loss': 0.0069489867255091665}
ETA: 9.5h -> 31.2h.

Epoch: 62:
{'categorical_accuracy': 0.4439333333333333, 'val_loss': 0.006717992033064365}
ETA: 9.6h -> 31.1h.

Epoch: 63:
{'categorical_accuracy': 0.45213333333333316, 'val_loss': 0.006641222989559174}
Best val_ accuracy: 0.4521.
ETA: 9.7h -> 30.9h.

Epoch: 64:
{'categorical_accuracy': 0.4395333333333331, 'val_loss': 0.006811788688600063}
ETA: 9.8h -> 30.8h.

Epoch: 65:
{'categorical_accuracy': 0.42853333333333304, 'val_loss': 0.006839821375906468}
ETA: 10.0h -> 30.6h.

Epoch: 66:
{'categorical_accuracy': 0.42993333333333306, 'val_loss': 0.006899107986688614}
ETA: 10.1h -> 30.5h.

Epoch: 67:
{'categorical_accuracy': 0.4338666666666666, 'val_loss': 0.006759329299628735}
ETA: 10.2h -> 30.4h.

Epoch: 68:
{'categorical_accuracy': 0.44179999999999986, 'val_loss': 0.006722223265469074}
ETA: 10.3h -> 30.2h.

Epoch: 69:
{'categorical_accuracy': 0.43613333333333315, 'val_loss': 0.006680303138494491}
ETA: 10.4h -> 30.2h.

Epoch: 70:
{'categorical_accuracy': 0.43853333333333316, 'val_loss': 0.006656442838907242}
ETA: 10.6h -> 30.2h.

