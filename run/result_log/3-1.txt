{'augment': False,
 'backbone_class': 'ConvNet',
 'balance': 1.0,
 'batch_size': 16,
 'cuda_seed': 929,
 'data_path': '/mnt/data3/lus/zhangyk/data/ye',
 'dataset': 'MiniImageNet',
 'distance': 'l2',
 'drop_lr_every': 40,
 'episodes_per_test_epoch': 10000,
 'episodes_per_train_epoch': 200,
 'episodes_per_val_epoch': 200,
 'epoch_verbose': False,
 'fce': False,
 'fix_BN': False,
 'gamma': 0.4,
 'gpu': '3',
 'init_weights': None,
 'inner_lr': 0.4,
 'inner_train_steps': 1,
 'inner_val_steps': 3,
 'log_interval': 50,
 'logger_filename': '/logs',
 'loss_fn': 'nn-cross_entropy',
 'lr': 0.0001,
 'lr_mul': 10.0,
 'lr_scheduler': 'step',
 'matching_lstm_layers': 1,
 'matching_unrolling_steps': 2,
 'max_epoch': 200,
 'meta': False,
 'meta_batch_size': 1,
 'meta_lr': 0.001,
 'metric_func': 'categorical_accuracy',
 'metrics': 'categorical_accuracy',
 'model_class': 'ProtoNet',
 'model_filepath': '/mnt/data3/lus/zhangyk/models/ProtoNet/0222 14-55-26-324 '
                   'ProtoNet MiniImageNet ConvNet-backbone l2 '
                   '5-1-15_train-w-s-q 5-1-15_val-w-s-q 5-1-15_test-w-s-q.pth',
 'model_filepath_test_best': '/mnt/data3/lus/zhangyk/models/ProtoNet/test_best/0222 '
                             '14-55-26-324 ProtoNet MiniImageNet '
                             'ConvNet-backbone l2 5-1-15_train-w-s-q '
                             '5-1-15_val-w-s-q 5-1-15_test-w-s-q.pth',
 'model_save_path': '/mnt/data3/lus/zhangyk/models',
 'mom': 0.9,
 'np_seed': 929,
 'num_input_channels': 3,
 'num_tasks': 4,
 'num_workers': 4,
 'order': 1,
 'orig_imsize': -1,
 'params_str': '0222 14-55-26-324 ProtoNet MiniImageNet ConvNet-backbone l2 '
               '5-1-15_train-w-s-q 5-1-15_val-w-s-q 5-1-15_test-w-s-q',
 'pretrain_mode': False,
 'relation_hidden_dim': 8,
 'save_dir': './checkpoints',
 'simpleshot': False,
 'simpleshot_episodes_per_epoch': 100,
 'simpleshot_num_nn': 1,
 'step_size': '50',
 'temperature': 64.0,
 'temperature2': 16.0,
 'test_interval': 0,
 'test_model_filepath': None,
 'test_query': 15,
 'test_shot': 1,
 'test_way': 5,
 'time_str': '0222 14-55-26-324',
 'torch_seed': 929,
 'train_mode': True,
 'train_query': 15,
 'train_shot': 1,
 'train_way': 5,
 'val_interval': 1,
 'val_query': 15,
 'val_shot': 1,
 'val_way': 5,
 'verbose': True,
 'weight_decay': 0.0005,
 'z_comment': 'Here are some comments for the current training process.'}
Begin training...
Epoch: 1:
{'categorical_accuracy': 0.29379999999999995, 'val_loss': 0.00783455331325531}
Best val_ accuracy: 0.2938.
ETA: 9m -> 30.9h.

Epoch: 2:
{'categorical_accuracy': 0.30646666666666655, 'val_loss': 0.007788354790210724}
Best val_ accuracy: 0.3065.
ETA: 21m -> 34.5h.

Epoch: 3:
{'categorical_accuracy': 0.3072666666666665, 'val_loss': 0.007742382436990738}
Best val_ accuracy: 0.3073.
ETA: 34m -> 38.3h.

Epoch: 4:
{'categorical_accuracy': 0.31626666666666653, 'val_loss': 0.007730324512720108}
Best val_ accuracy: 0.3163.
ETA: 48m -> 40.1h.

Epoch: 5:
{'categorical_accuracy': 0.33346666666666663, 'val_loss': 0.007675748220086098}
Best val_ accuracy: 0.3335.
ETA: 1.0h -> 41.1h.

Epoch: 6:
{'categorical_accuracy': 0.32880000000000004, 'val_loss': 0.0076781144231557845}
ETA: 1.3h -> 41.9h.

Epoch: 7:
{'categorical_accuracy': 0.3225333333333333, 'val_loss': 0.007648084238171577}
ETA: 1.5h -> 41.6h.

Epoch: 8:
{'categorical_accuracy': 0.33686666666666637, 'val_loss': 0.00767312522828579}
Best val_ accuracy: 0.3369.
ETA: 1.7h -> 41.8h.

Epoch: 9:
{'categorical_accuracy': 0.3311999999999999, 'val_loss': 0.007639725062251091}
ETA: 1.9h -> 42.1h.

Epoch: 10:
{'categorical_accuracy': 0.3599333333333333, 'val_loss': 0.007474650427699089}
Best val_ accuracy: 0.3599.
ETA: 2.1h -> 42.3h.

Epoch: 11:
{'categorical_accuracy': 0.33686666666666654, 'val_loss': 0.007602752858400345}
ETA: 2.3h -> 42.1h.

Epoch: 12:
{'categorical_accuracy': 0.35859999999999986, 'val_loss': 0.007470564550161362}
ETA: 2.5h -> 42.2h.

Epoch: 13:
{'categorical_accuracy': 0.3716666666666667, 'val_loss': 0.007398097988963127}
Best val_ accuracy: 0.3717.
ETA: 2.7h -> 42.0h.

Epoch: 14:
{'categorical_accuracy': 0.3695333333333331, 'val_loss': 0.007431143569946289}
ETA: 2.9h -> 41.7h.

Epoch: 15:
{'categorical_accuracy': 0.3686000000000002, 'val_loss': 0.007388133522868157}
ETA: 3.1h -> 41.6h.

Epoch: 16:
{'categorical_accuracy': 0.35026666666666645, 'val_loss': 0.007477934256196021}
ETA: 3.3h -> 41.2h.

Epoch: 17:
{'categorical_accuracy': 0.37459999999999993, 'val_loss': 0.007360549464821815}
Best val_ accuracy: 0.3746.
ETA: 3.5h -> 41.0h.

Epoch: 18:
{'categorical_accuracy': 0.3754666666666666, 'val_loss': 0.007408638229966164}
Best val_ accuracy: 0.3755.
ETA: 3.7h -> 40.9h.

Epoch: 19:
{'categorical_accuracy': 0.36953333333333327, 'val_loss': 0.007404353350400925}
ETA: 3.9h -> 40.8h.

Epoch: 20:
{'categorical_accuracy': 0.3764666666666664, 'val_loss': 0.007334355992078782}
Best val_ accuracy: 0.3765.
ETA: 4.1h -> 40.9h.

Epoch: 21:
{'categorical_accuracy': 0.3707333333333333, 'val_loss': 0.007358444598317146}
ETA: 4.3h -> 40.8h.

Epoch: 22:
{'categorical_accuracy': 0.3667333333333333, 'val_loss': 0.007412749186158181}
ETA: 4.5h -> 40.6h.

Epoch: 23:
{'categorical_accuracy': 0.37686666666666646, 'val_loss': 0.007310989359021187}
Best val_ accuracy: 0.3769.
ETA: 4.7h -> 40.5h.

Epoch: 24:
{'categorical_accuracy': 0.3669333333333331, 'val_loss': 0.007421310821175575}
ETA: 4.8h -> 40.3h.

Epoch: 25:
{'categorical_accuracy': 0.3806666666666662, 'val_loss': 0.007327971911430359}
Best val_ accuracy: 0.3807.
ETA: 5.0h -> 40.1h.

Epoch: 26:
{'categorical_accuracy': 0.3779333333333332, 'val_loss': 0.007276593881845475}
ETA: 5.2h -> 39.7h.

Epoch: 27:
{'categorical_accuracy': 0.379, 'val_loss': 0.007328448411822319}
ETA: 5.3h -> 39.3h.

Epoch: 28:
{'categorical_accuracy': 0.3803333333333332, 'val_loss': 0.007314452916383743}
ETA: 5.5h -> 39.0h.

Epoch: 29:
{'categorical_accuracy': 0.3943333333333333, 'val_loss': 0.007226408416032792}
Best val_ accuracy: 0.3943.
ETA: 5.6h -> 38.8h.

Epoch: 30:
{'categorical_accuracy': 0.38633333333333353, 'val_loss': 0.00725936448276043}
ETA: 5.8h -> 38.5h.

Epoch: 31:
{'categorical_accuracy': 0.3833333333333331, 'val_loss': 0.00727975409924984}
ETA: 5.9h -> 38.2h.

Epoch: 32:
{'categorical_accuracy': 0.39133333333333303, 'val_loss': 0.007209727963805199}
ETA: 6.1h -> 37.9h.

Epoch: 33:
{'categorical_accuracy': 0.3835333333333334, 'val_loss': 0.0072301363438367836}
ETA: 6.2h -> 37.6h.

Epoch: 34:
{'categorical_accuracy': 0.3909333333333331, 'val_loss': 0.007229084658622742}
ETA: 6.3h -> 37.3h.

Epoch: 35:
{'categorical_accuracy': 0.3694000000000001, 'val_loss': 0.007312603336572647}
ETA: 6.5h -> 37.0h.

Epoch: 36:
{'categorical_accuracy': 0.39059999999999995, 'val_loss': 0.007159801733493804}
ETA: 6.6h -> 36.7h.

Epoch: 37:
{'categorical_accuracy': 0.3859333333333332, 'val_loss': 0.00719088152050972}
ETA: 6.7h -> 36.5h.

Epoch: 38:
{'categorical_accuracy': 0.40726666666666633, 'val_loss': 0.007045242527127266}
Best val_ accuracy: 0.4073.
ETA: 6.9h -> 36.2h.

Epoch: 39:
{'categorical_accuracy': 0.39433333333333354, 'val_loss': 0.007093030115962029}
ETA: 7.0h -> 36.0h.

Epoch: 40:
{'categorical_accuracy': 0.4002000000000001, 'val_loss': 0.007105819398164749}
ETA: 7.1h -> 35.7h.

Epoch: 41:
{'categorical_accuracy': 0.3901999999999999, 'val_loss': 0.0071959320217370995}
ETA: 7.3h -> 35.5h.

Epoch: 42:
{'categorical_accuracy': 0.41166666666666657, 'val_loss': 0.007056308963894844}
Best val_ accuracy: 0.4117.
ETA: 7.4h -> 35.2h.

Epoch: 43:
{'categorical_accuracy': 0.3919333333333329, 'val_loss': 0.007165528118610383}
ETA: 7.5h -> 35.0h.

Epoch: 44:
{'categorical_accuracy': 0.3914666666666669, 'val_loss': 0.0071554671272635465}
ETA: 7.7h -> 34.8h.

Epoch: 45:
{'categorical_accuracy': 0.40599999999999986, 'val_loss': 0.007091917291283607}
ETA: 7.8h -> 34.6h.

Epoch: 46:
{'categorical_accuracy': 0.40733333333333344, 'val_loss': 0.007096957615017892}
ETA: 7.9h -> 34.3h.

Epoch: 47:
{'categorical_accuracy': 0.39173333333333327, 'val_loss': 0.007170019537210465}
ETA: 8.0h -> 34.1h.

Epoch: 48:
{'categorical_accuracy': 0.40326666666666644, 'val_loss': 0.007106187978386878}
ETA: 8.1h -> 33.8h.

Epoch: 49:
{'categorical_accuracy': 0.3998666666666666, 'val_loss': 0.007098511949181556}
ETA: 8.2h -> 33.6h.

Epoch: 50:
{'categorical_accuracy': 0.41233333333333333, 'val_loss': 0.006985342863202095}
Best val_ accuracy: 0.4123.
ETA: 8.3h -> 33.4h.

Epoch: 51:
{'categorical_accuracy': 0.4111333333333331, 'val_loss': 0.0070016727745532996}
ETA: 8.4h -> 33.1h.

Epoch: 52:
{'categorical_accuracy': 0.391733333333333, 'val_loss': 0.007103103080391884}
ETA: 8.6h -> 32.9h.

Epoch: 53:
{'categorical_accuracy': 0.39766666666666695, 'val_loss': 0.007031394863128661}
ETA: 8.7h -> 32.7h.

Epoch: 54:
{'categorical_accuracy': 0.4029999999999997, 'val_loss': 0.0070102665990591055}
ETA: 8.8h -> 32.5h.

Epoch: 55:
{'categorical_accuracy': 0.4026000000000003, 'val_loss': 0.007057676035165787}
ETA: 8.9h -> 32.3h.

Epoch: 56:
{'categorical_accuracy': 0.4138666666666665, 'val_loss': 0.0069667844504117974}
Best val_ accuracy: 0.4139.
ETA: 9.0h -> 32.1h.

Epoch: 57:
{'categorical_accuracy': 0.4175333333333331, 'val_loss': 0.006900832641124725}
Best val_ accuracy: 0.4175.
ETA: 9.1h -> 31.9h.

Epoch: 58:
{'categorical_accuracy': 0.4024666666666667, 'val_loss': 0.006961318057775497}
ETA: 9.2h -> 31.7h.

Epoch: 59:
{'categorical_accuracy': 0.4143999999999999, 'val_loss': 0.007000641545653343}
ETA: 9.3h -> 31.5h.

Epoch: 60:
{'categorical_accuracy': 0.41473333333333334, 'val_loss': 0.006941625486314297}
ETA: 9.4h -> 31.4h.

Epoch: 61:
{'categorical_accuracy': 0.4108000000000001, 'val_loss': 0.006985672935843468}
ETA: 9.5h -> 31.2h.

Epoch: 62:
{'categorical_accuracy': 0.4251333333333334, 'val_loss': 0.006935780823230744}
Best val_ accuracy: 0.4251.
ETA: 9.6h -> 31.0h.

Epoch: 63:
{'categorical_accuracy': 0.4195333333333333, 'val_loss': 0.006872318622469902}
ETA: 9.7h -> 30.9h.

Epoch: 64:
{'categorical_accuracy': 0.4144666666666662, 'val_loss': 0.006913820391893387}
ETA: 9.8h -> 30.8h.

Epoch: 65:
{'categorical_accuracy': 0.4192666666666666, 'val_loss': 0.006922860687971115}
ETA: 10.0h -> 30.6h.

Epoch: 66:
{'categorical_accuracy': 0.4132666666666666, 'val_loss': 0.0069888519465923305}
ETA: 10.1h -> 30.5h.

Epoch: 67:
{'categorical_accuracy': 0.42426666666666646, 'val_loss': 0.006910186809301376}
ETA: 10.2h -> 30.3h.

Epoch: 68:
{'categorical_accuracy': 0.41519999999999996, 'val_loss': 0.0068822918415069574}
ETA: 10.3h -> 30.2h.

Epoch: 69:
{'categorical_accuracy': 0.41253333333333303, 'val_loss': 0.006929889756441116}
ETA: 10.4h -> 30.2h.

Epoch: 70:
{'categorical_accuracy': 0.4101333333333335, 'val_loss': 0.006957686957716942}
ETA: 10.6h -> 30.2h.

